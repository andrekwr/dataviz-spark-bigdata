{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "import math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuração inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(appName=\"Teste\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.sequenceFile(\"pages/part-00000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total de documentos na base\n",
    "total_docs = rdd.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funções de tratamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quantas ocorrencias da palavra em todos documentos\n",
    "def conta_palavras(item):\n",
    "    texto = item[1]\n",
    "    palavras = texto.strip().split()\n",
    "    return [(palavra.lower(),1) for palavra in palavras]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conta quantos docs cada palavra aparece\n",
    "def conta_docs(item):\n",
    "    texto = item[1]\n",
    "    palavras = texto.strip().split()\n",
    "    return [(palavra.lower(),1) for palavra in set(palavras)]\n",
    "rdd_docs_word = rdd.flatMap(conta_docs).reduceByKey(lambda x,y: x + y).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtra palavras que aparecem em certa quantidade de docs\n",
    "doc_freq_min = 10\n",
    "doc_freq_max = 0.7 * total_docs\n",
    "def filtra(item):\n",
    "    contagem = item[1]\n",
    "    return (contagem < doc_freq_max) and (contagem > doc_freq_min)\n",
    "\n",
    "#RDD com quantos docs cada palavra aparece considerando intervalo limite de 5 a 0.7*total_documentos\n",
    "rdd_docs_filtrado = rdd_docs_word.filter(filtra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Análise do vocabulário comum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pons', 3.4117759853793284),\n",
       " ('r$', 0.5932673172690647),\n",
       " ('//}', 3.3274550996792924),\n",
       " ('à', 0.32189609502544525),\n",
       " ('e-mail', 0.43047524320596725),\n",
       " ('bom', 0.8289013117853762),\n",
       " ('joaquim', 1.6987657237630354),\n",
       " ('cantores', 2.5086859983873846),\n",
       " ('região', 0.881576287176246),\n",
       " ('*', 0.864528870032381)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calcula idf de cada palavra filtrada\n",
    "def computa_idf(item):\n",
    "    palavra, contagem = item\n",
    "    idf = math.log10(total_docs / contagem)\n",
    "    return (palavra, idf)\n",
    "rdd_idf = rdd_docs_filtrado.map(computa_idf)\n",
    "rdd_idf.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Análise do vocabulário específico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtrar RDDs para selecionar conjuntos com cada palavra definida.\n",
    "rdd_oreo = rdd.filter(lambda x: \"oreo\" in x[1]) \n",
    "rdd_negresco = rdd.filter(lambda x: \"negresco\" in x[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cálculo da frequência para os RDDs dos dois conjuntos.\n",
    "rdd_freq_oreo = rdd_oreo.flatMap(conta_palavras).reduceByKey(lambda x,y: x + y).map(lambda x: (x[0], math.log10(1 + x[1]))).cache()\n",
    "rdd_freq_negresco = rdd_negresco.flatMap(conta_palavras).reduceByKey(lambda x,y: x + y).map(lambda x: (x[0], math.log10(1 + x[1]))).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intersecção dos dois conjuntos de frequência.\n",
    "rdd_inter = rdd_freq_oreo.intersection(rdd_freq_negresco)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tabela com 100 palavras mais relevantes onde os dois itens aparecem conjuntamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcula 100 palavras mais relevantes em conjunto às palavras escolhidas\n",
    "rdd_all = rdd_inter.join(rdd_idf).map(lambda x: (x[0], x[1][0]*x[1][1])).takeOrdered(100, key=lambda x: -x[1])\n",
    "df = pd.DataFrame(rdd_all, columns = [\"palavra\", \"relevancia\"]).to_csv(\"rdd_all.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tabela com 100 palavras mais relevantes sem a presença de \"negresco\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcula 100 palavras mais relevantes com apenas do conjunto Oreo\n",
    "rdd_oreo = rdd_freq_oreo.subtractByKey(rdd_freq_negresco).join(rdd_idf).map(lambda x: (x[0], x[1][0]*x[1][1])).takeOrdered(100, key=lambda x: -x[1])\n",
    "df_o = pd.DataFrame(rdd_oreo, columns = [\"palavra\", \"relevancia\"]).to_csv(\"rdd_oreo.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tabela com 100 palavras mais relevantes sem a presença de \"oreo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcula 100 palavras mais relevantes com apenas do conjunto Negresco\n",
    "rdd_negresco = rdd_freq_negresco.subtractByKey(rdd_freq_oreo).join(rdd_idf).map(lambda x: (x[0], x[1][0]*x[1][1])).takeOrdered(100, key=lambda x: -x[1])\n",
    "df_n = pd.DataFrame(rdd_negresco, columns = [\"palavra\", \"relevancia\"]).to_csv(\"rdd_negresco.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
